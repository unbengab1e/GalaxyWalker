{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/mnt/data/CVPR2025/task1_data/images_features\"\n",
    "def load_features(save_dir, batch_num):\n",
    "    \"\"\"加载指定批次的特征\"\"\"\n",
    "    file_path = os.path.join(save_dir, f'features_batch_{batch_num}.pt')\n",
    "    data_dict = torch.load(file_path)\n",
    "    return data_dict['features'], data_dict['image_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_637971/3112141527.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_dict = torch.load(file_path)\n"
     ]
    }
   ],
   "source": [
    "features, image_paths = load_features(save_dir, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/data/CVPR2025/task1_data/images/images/39632936139492141.png',\n",
       " '/mnt/data/CVPR2025/task1_data/images/images/39632936139492779.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[:2]\n",
    "image_id = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "from astropy.table import Table\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def bf16_to_uint16(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"将bf16张量转换为uint16数组进行存储\"\"\"\n",
    "    return tensor.view(dtype=torch.uint16).numpy()\n",
    "\n",
    "def uint16_to_bf16(array: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\"将uint16数组转换回bf16张量\"\"\"\n",
    "    return torch.from_numpy(array).view(dtype=torch.bfloat16)\n",
    "\n",
    "def merge_feature_batches(save_dir: str, output_file: str, feature_shape: tuple = (4, 1601)):\n",
    "    \"\"\"\n",
    "    将所有批次的特征文件合并到一个HDF5文件中，使用内存映射方式处理\n",
    "    \n",
    "    Args:\n",
    "        save_dir: 特征文件所在目录\n",
    "        output_file: 输出HDF5文件路径\n",
    "        feature_shape: 每个特征的形状，默认为(4, 1601)\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # 首先统计总样本数和收集所有的image_paths\n",
    "    total_samples = 0\n",
    "    all_image_paths = []\n",
    "    batch_files = []\n",
    "    \n",
    "    print(\"Counting total samples...\")\n",
    "    for batch_num in trange(1000):  # 设置一个足够大的上限\n",
    "        file_path = os.path.join(save_dir, f'features_batch_{batch_num}.pt')\n",
    "        if not os.path.exists(file_path):\n",
    "            break\n",
    "        \n",
    "        # 只加载元信息\n",
    "        data_dict = torch.load(file_path, map_location='cpu')\n",
    "        total_samples += len(data_dict['features'])\n",
    "        all_image_paths.extend(data_dict['image_paths'])\n",
    "        batch_files.append(file_path)\n",
    "        \n",
    "        # 释放内存\n",
    "        del data_dict\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if not batch_files:\n",
    "        raise ValueError(f\"No feature files found in {save_dir}\")\n",
    "    \n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    \n",
    "    # 从图像路径中提取targetID\n",
    "    target_ids = [Path(p).stem for p in all_image_paths]\n",
    "    \n",
    "    # 创建targetID到index的映射\n",
    "    id_to_idx = {tid: idx for idx, tid in enumerate(target_ids)}\n",
    "    \n",
    "    # 创建HDF5文件\n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        # 创建特征数据集，使用uint16存储bf16数据\n",
    "        features_dataset = f.create_dataset(\n",
    "            'features', \n",
    "            shape=(total_samples, *feature_shape),\n",
    "            dtype='uint16',\n",
    "            chunks=(1, *feature_shape),  # 每个样本作为一个chunk\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=4\n",
    "        )\n",
    "        \n",
    "        # 写入特征\n",
    "        current_idx = 0\n",
    "        for file_path in tqdm(batch_files, desc=\"Merging features\"):\n",
    "            # 逐个批次加载并写入\n",
    "            data_dict = torch.load(file_path, map_location='cpu')\n",
    "            batch_features = data_dict['features']  # shape: (batch_size, 4, 1601)\n",
    "            \n",
    "            # 确保形状正确\n",
    "            if batch_features.shape[1:] != feature_shape:\n",
    "                raise ValueError(f\"Unexpected feature shape: {batch_features.shape[1:]}, expected {feature_shape}\")\n",
    "            \n",
    "            # 转换为uint16并保存\n",
    "            batch_features_uint16 = bf16_to_uint16(batch_features)\n",
    "            batch_size = len(batch_features)\n",
    "            \n",
    "            features_dataset[current_idx:current_idx + batch_size] = batch_features_uint16\n",
    "            current_idx += batch_size\n",
    "            \n",
    "            # 释放内存\n",
    "            del data_dict, batch_features, batch_features_uint16\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # 将id_to_idx映射保存为属性\n",
    "        f.attrs['id_to_idx'] = json.dumps(id_to_idx)\n",
    "        # 保存特征形状信息\n",
    "        f.attrs['feature_shape'] = json.dumps(feature_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting total samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_637971/633050733.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_dict = torch.load(file_path, map_location='cpu')\n",
      "  6%|▌         | 55/1000 [10:53<3:07:12, 11.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmerge_feature_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/data/CVPR2025/task1_data/images_features.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m, in \u001b[0;36mmerge_feature_batches\u001b[0;34m(save_dir, output_file, feature_shape)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 只加载元信息\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     46\u001b[0m all_image_paths\u001b[38;5;241m.\u001b[39mextend(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_paths\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/mnt/data/CVPR2025/miniconda3/envs/astroclip/lib/python3.9/site-packages/torch/serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/mnt/data/CVPR2025/miniconda3/envs/astroclip/lib/python3.9/site-packages/torch/serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m/mnt/data/CVPR2025/miniconda3/envs/astroclip/lib/python3.9/site-packages/torch/serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/mnt/data/CVPR2025/miniconda3/envs/astroclip/lib/python3.9/site-packages/torch/serialization.py:1772\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1769\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset : storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1771\u001b[0m     storage \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1772\u001b[0m         \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m         \u001b[38;5;241m.\u001b[39m_typed_storage()\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1775\u001b[0m     )\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "merge_feature_batches(save_dir, output_file=\"/mnt/data/CVPR2025/task1_data/images_features.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
